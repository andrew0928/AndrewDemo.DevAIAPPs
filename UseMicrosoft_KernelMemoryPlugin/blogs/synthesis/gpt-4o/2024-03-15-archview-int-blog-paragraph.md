## 段落0, 寫在前面
本文延續前兩篇LLM應用開發的探討，聚焦於資料處理的領域，特別是資料檢索的應用。作者分享了如何利用LLM替應用程式增加智能化，並以自身的部落格作為示範，探索AI如何提升資料檢索和應用效率。藉由與Azure OpenAI的整合，實現RAG機制，並探討了技術的優勢與應用前景。

## 段落1, "安德魯的部落格" GPTs - Demo
作者介紹了"安德魯的部落格GPTs"，一個結合過去20年文章的對話AI系統，示範如何利用AI整理和導讀大量部落格內容。文章展示了系統如何根據用戶需求，透過AI檢索和總結相關資料，並提供解決方案。此外，也探討了AI如何克服長篇內容不易消化的問題，提升資料的長期價值。

## 段落2, 部落格檢索服務
此段深入解釋RAG的基本架構以及作者如何實現它。從資料分割與向量化開始，透過Kernel Memory提供檢索能力，並結合GPTs進行語意合成。文章利用Azure服務和開源專案搭建整個流程，實現輕鬆的語意檢索與應用的可能性，並分享了在開發過程中的經驗與心得。

## 段落3, AI改變了內容搜尋方式
AI正改變內容搜尋的方式，從傳統關鍵字搜尋轉向語意搜尋。透過文本嵌入和向量資料庫，實現更精準的語意比對和相關性檢索。作者探討技術的演進如何影響資料查詢和應用程序運作的層次變化。文章指出AI應用將資料操作從條件過濾轉向語意分析，並推測未來向量為索引的應用可能帶來的變革。

## 段落4, 結論
本文總結了AI應用於智能化資料檢索的潛力，強調在AI成熟年代，資訊技術的基礎需轉向對LLM、嵌入向量、提示工程等知識的掌握。作者分享自己在此領域的探索心得，提供給其他架構師參考，並指出在AI時代中，應避免與AI競賽，而應思考如何有效利用AI工具增強自身價值。