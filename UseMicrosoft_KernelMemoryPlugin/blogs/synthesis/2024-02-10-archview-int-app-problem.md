Case 1: 將LLM融入結帳流程  
- Problem: 在關鍵功能（如結帳）時，系統難以自動判斷用戶行為是否具有潛在風險或不合理性。  
- RootCause: 傳統邏輯靠rule-based規則，不易判讀自然語言描述；也缺乏「常識」層面的判斷，如未成年購酒、過量含糖飲品、漏下購物需求等。  
- Resolution: 在結帳流程中嵌入AI判斷機制，透過System Prompt定位「店長」角色，由LLM替使用者列出可能的法律限制、健康疑慮、操作錯誤等。  
- Example: 使用者在輸入「小孩生日派對」與「啤酒」等關鍵字時，AI判斷可能觸及未成年購酒問題，回覆「HINT」並提醒注意法律規範。  

Case 2: 即時Copilot提示使用者操作異常  
- Problem: 使用者可能在購物車頻繁加入與移除相同商品，或重複輸入同一指令，導致操作錯誤或混亂。  
- RootCause: 傳統流程只能依照固定指令進行；若使用者多次操作，系統通常不會「主動」偵測到潛在問題。  
- Resolution: 每次操作都封裝成Prompt傳給LLM，由LLM辨識操作模式並回覆「OK」或「HINT」，若偵測到異常行為就及時提出建議。  
- Example: 使用者重複在購物車加入、移除啤酒5次後，AI回覆「HINT」，主動詢問是否遇到問題、要不要提供協助。  

Case 3: 自然語言對話中自動完成多步操作  
- Problem: 使用者以句子表達複雜需求（如「預算1000元，要買啤酒10罐、可樂10罐，剩下買綠茶」），不易對應程式端多支API呼叫；若看不懂用戶意圖就無法完成購物流程。  
- RootCause: 多數程式僅能接收單一指令或明確參數，不具備語意推理能力；過去需要使用者自行拆解需求，多次點擊才能完成操作。  
- Resolution: 利用FunctionCalling（或Plugins）機制記錄「加入購物車」「列出商品」等功能，並在描述中定義參數用法和回傳形式，讓LLM可自動呼叫正確函式。  
- Example: 使用者只需輸入一句話描述購買組合與預算，LLM自行呼叫多個API完成各商品加入、試算金額，再列出購物車確認，最後幫使用者做好結帳前檢查。  

Case 4: RAG與企業知識庫應用  
- Problem: 當產品線或規範文件龐大時，開發者難以在每次對話都塞入全部資料，導致AI回答仍可能缺乏企業特定規範或FAQ細節。  
- RootCause: LLM本身無法儲存大量企業內部訊息；若僅用Prompt大量附帶文字會造成Token成本過高並可能混淆AI。  
- Resolution: 將企業知識透過Embedding儲存在向量資料庫，詢問時先用語意檢索過濾出關聯文件，再交給LLM整合生成回覆。  
- Example: 當使用者問到「本店素食商品是否有折扣？」時，系統先以Embedding搜索企業資料庫的「折扣與促銷」篇章，再讓AI摻入回覆，並避免回答到不適用之資訊。  

Case 5: 開發者面臨Prompt與API設計難題  
- Problem: LLM語意理解尚有不確定性，若提示工程或API描述不精準，AI可能出錯或呼叫錯誤函式，造成系統行為難以預測。  
- RootCause: 傳統程式開發習慣都是精準function call；LLM改以自然語言當輸入，需要調整既有架構與新思維來撰寫Prompt與技能描述。  
- Resolution: 用明確的Description標示函式用途與參數格式，並善用「店長」或「助理」角色限制：要嘛輸出OK或HINT、只在特定條件呼叫函式，逐步縮小AI誤判範圍。  
- Example: 於結帳階段，要求AI只可回傳「OK:…」或「HINT:…」，否則就視為無效訊息，能有效強化AI在預期範圍內使用功能，並降低幻覺風險。  