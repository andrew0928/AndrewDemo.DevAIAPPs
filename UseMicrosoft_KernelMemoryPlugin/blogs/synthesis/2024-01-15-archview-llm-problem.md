Case 1: API 設計與 AI 整合  
- Problem: 過去以「能動就好」為目標的 API 設計，易讓 LLM 誤判或誤呼叫介面。  
- RootCause: API 與業務邏輯不夠吻合，沒有明確流程定義，缺乏對狀態與參數的嚴謹規範。  
- Resolution: 推動「AI Friendly」API 設計，採取 API First、DDD 或類似概念，確保每個端點皆能自我解釋、易於文件化、狀態明確。  
- Example: 安德魯小舖 GPTs 一開始 API 僅提供基本功能，導致 GPTs 在擷取預算、折扣規則等細節時手忙腳亂；更改 API 規格並搭配標準化文件後，成功提高 LLM 正確性。  

Case 2: OAuth 認證流程對 LLM 使用者的衝擊  
- Problem: LLM 在呼叫 API 時，需要認證與授權，但傳統 OAuth 流程對「對話式 AI」不夠直覺。  
- RootCause: 使用者端與 LLM 無法共享 token 之間的流程，導致無法順利完成登入並維持會話狀態。  
- Resolution: 重構或精簡認證機制，讓 LLM 能輕鬆完成授權。可考慮簡化 OAuth 流程或提供一次性登入 API，並在對話初期即處理認證邏輯。  
- Example: 作者最初嘗試讓 GPTs 直接呼叫帶 token 的 API，出現大批認證錯誤；重新調整為更標準化的 OAuth 與使用者登入介面後，GPTs 便能順利呼叫後續購物流程。  

Case 3: 計算與意圖分界不清  
- Problem: 高度精準計算的需求（例如金額、折扣、數學運算）若完全交給 LLM，可能引發錯誤或結果不穩定。  
- RootCause: LLM 的回答帶有機率性，且並非為精準數值計算設計；若缺乏明確 API 辅助，很容易產生偏差。  
- Resolution: 針對核心交易、統計、或技術性計算，應該另行開發可驗證的後端邏輯，並讓 AI 呼叫這些函數或 API。LLM 只負責理解意圖與溝通。  
- Example: 結帳時若將折扣計算全丟給 GPTs，可能得到不一致折扣結果；改用後端 API 處理後，則能確保金額正確、訊息回傳穩定。  

Case 4: 舊式 UI 流程與新式對話體驗衝突  
- Problem: 傳統 UI 設計以「使用者逐步完成表單」為導向，無法滿足 LLM 「一次接收所有需求」的對話模式。  
- RootCause: 使用者界面與後台分工過度緊密；流程切割依賴固定步驟與人工作業，難以適配 AI 的多步驟整合。  
- Resolution: 重構使用者體驗，以對話或自然語言為核心，將 UI 成為輔助工具，用於填寫必要欄位或做視覺化，而非全面掌控流程。  
- Example: 搭配 GPTs 的購物系統，若仍使用很多複雜表單分頁，對話體驗會反覆被中斷；將欄位簡化、改為 AI 驅動，再由 UI 獲取必要輸入，則能順暢完成整個購物對談。  

Case 5: Prompt 與文件說明不足導致 AI 誤解  
- Problem: AI 依賴 Prompt 了解可呼叫的接口，若文件與敘述不完整或不精準，LLM 容易誤判。  
- RootCause: 開發者只寫 API 規格，卻忽略以自然語言清晰描述每個端點的功能、輸入輸出與限制。  
- Resolution: 增加文件陳述，包括範例、錯誤處理與實際使用情境，並於 Prompt 設定添入對 API 行為的詳細解釋，提高 AI 溝通效率。  
- Example: 最初作者僅有 Swagger 上的簡短摘要，GPTs 曾多次誤用查詢或帶入錯參數；補充端點說明與簡化描述後，GPTs 在正確時機成功呼叫對應功能。