Case 1: API 設計無法滿足 AI 需求  
- Problem: 傳統 API 過度貼合既有 UI 或單一次性需求，忽略通用性及狀態機設計，導致 AI 在呼叫 API 時需要大量額外 Prompt 引導、容易出現錯誤或資源浪費。  
- RootCause: 缺乏「API First」的設計思維，開發者常以臨時溝通或快速配合前端為優先，未照顧可重複使用的商業邏輯與一致化標準。  
- Resolution: 重新梳理服務的核心 Domain，建立清楚的狀態機與授權規範（Scope），釐清哪些 API 屬於基礎功能、哪些是合併便捷取用，並在設計階段就同步考慮 AI 工具訪問的需求。  
- Example: 以「安德魯小舖 GPTs」為例，採用簡潔而穩定的購物流程 API（查詢商品、加入購物車、結帳），狀態機明確定義等待付款、付款後狀態等，讓 GPT 能精準呼叫。

Case 2: AI 推論與系統邏輯衝突  
- Problem: AI 能自發判斷並呼叫 API，但有時會對同一段邏輯做超出系統邏輯範疇的操作（例如在尚未付款時就修改訂單狀態），造成資料不一致。  
- RootCause: AI 具有高彈性推論能力，若缺乏嚴謹的防呆機制與授權校驗，可能呼叫不該呼叫的 API 或無視商業規則。  
- Resolution: 在 API 設計中明確劃分角色與 Scope，限制 AI 僅能呼叫符合當前狀態或角色允許的端點。必要時於程式層面進行最後驗證與拒絕，確保狀態轉移符合原先設計。  
- Example: 訂單狀態必須先確認「已付款」才能執行「物流出貨」，否則撥錯 API 導致資料出錯。開發者在 swagger 或 function schema 中就應阻擋這類違規呼叫。

Case 3: 使用者體驗參差不齊，對話模型準確度不夠  
- Problem: AI 對於使用者意圖的解析易受上下文、口語表達不同所影響，導致推薦不精準或回覆資訊前後矛盾。  
- RootCause: LLM 在推論上具有不確定性，較難像傳統規則式系統那樣穩定。同時，Prompt 或對話中的指令不明確，也增加AI誤判風險。  
- Resolution: 選擇更高精度或針對領域微調（Fine-tuning）的模型；在系統端採多輪交互或檢查機制，必要時可由後端服務作關鍵字、狀態驗證。定期觀測用戶回饋，以優化對話流程與 Prompt。  
- Example: 「安德魯小舖 GPTs」會在用戶給出需求後，先確認是否有超出預算或商品缺貨，若缺失則用程式檢查並給出重新調整的建議 Prompt，引導 GPT 提供相符的結果。

Case 4: 結合企業知識庫的查詢不精準  
- Problem: 想透過 AI 替使用者解答企業內部文件或文章內容，但因模型原生知識不足或向量索引不完整，查詢效率與回答精準度大打折扣。  
- RootCause: 缺乏 RAG（Retrieval-Augmented Generation）流程或資料庫設計不佳，如未建立向量資料庫、索引過於粗糙或段落分割不適當。  
- Resolution: 規劃向量索引的建置與更新機制，將關鍵文章或文本執行 Embedding 並儲存於 VectorDB，配合 Ranking 或カテゴリ過濾；撰寫對應的檢索 API 或 Tool，引導 AI 拿到最相關片段再行回答。  
- Example: 「安德魯的部落格 GPTs」使用向量搜尋技術，每篇文章分割多段，並記錄在向量資料庫。AI 先執行檢索動作，將最吻合的段落加到 Prompt，最後歸納出結論。

Case 5: 無法整合 AI 到既有 CI/CD 環境  
- Problem: 團隊想把 AI 模型或促進 AI 推論的組件一起部署，但缺少適合的 Pipeline 協作，讓模型版本管理、部署測試與環境變更變得複雜。  
- RootCause: 傳統 CI/CD 流程僅聚焦於應用程式與設定檔，忽略了 AI 需要的模型更新、資料蒐集、向量索引維護，以及更高算力需求或 GPU 資源配置。  
- Resolution: 建立第四條（或專屬） AI Pipeline，將模型訓練、微調、部署納入版本控管；並且在雲端或本機 GPU 資源調度、更新向量資料庫等流程也要與程式碼的部署使用同一套 GitOps 思維管理。  
- Example: 在 Azure OpenAI 或其他雲服務上建置模型 Endpoints，腳本會自動在相同 Git Repository 中維護執行檔與部署設定，並統一與應用程式進行整合測試，確保多項組件的相容性。