Case 1: 大量文章難以搜尋與整理  
- Problem: 面對 327 篇、400 萬字的長篇技術文章，使用者常因內容龐雜而無法快速找到所需資訊。  
- RootCause: 傳統關鍵字搜尋難以精準定位語意類似段落，加上缺乏閱讀脈絡與摘要功能，導致檢索效率不佳。  
- Resolution: 採用 RAG 流程，先以 Embedding 建立向量資料庫，配合語意分析比對，最後透過 LLM 摘要與串聯回答。  
- Example: 在 GPTs 介面中，使用者只需自然語言描述需求，系統即透過箭頭式檢索加上 GPT4 生成，回覆與連結同時給出。  

Case 2: 段落切割與 Token 成本控制  
- Problem: 長文直接丟給 GPT 模型會超過 Token 限制，或造成生成成本飆高。  
- RootCause: GPT4 處理一次 Token 數量有限，且 Token 帶來費用；若不分段處理，易在效能與開銷方面失衡。  
- Resolution: 透過 Chunking 策略按段落或字數分割文本，控制單次向量轉換的規模，提高檢索與對話效率。  
- Example: 部落格文章被分成多個小段落，單篇文可生成數十個 Embedding，最後集結成向量資料庫，減少一次性處理量。  

Case 3: 檢索結果與 Chat 之間的對話調控  
- Problem: 使用者多次對 Chat AI 追問，但部分回應內容不具連續性或遺漏文章連結。  
- RootCause: LLM 產生懶惰回答，或沒有再次呼叫檢索 API；上下文提示設計不足可能也導致資訊斷層。  
- Resolution: 於 GPTs 設定適當的系統提示 (Prompt Engineering)，並於 swagger(OpenAPI) 上標記清楚路徑與觸發條件，讓 GPT 能自動判別何時重查資料。  
- Example: 作者多次追問微服務、家用設備及資料一致性範例時，檢索服務就能再次被 GPTs 呼叫，補充對應文章連結與說明。  

Case 4: 權限與安全的分眾檢索  
- Problem: 向量資料庫無法直接處理複雜的使用者層級權限需求。  
- RootCause: 向量查詢僅能評估語意相似度，缺乏角色或標籤過濾時，可能將不適合的內容也一併回傳。  
- Resolution: 利用 Tag 進行 Metadata 標記，讓每篇資料顯示用戶或分類標籤，再在檢索階段進行欄位過濾，保障資料安全。  
- Example: 安德魯於匯入文章時注記 categories、user-tags 等標籤；系統可於查詢時過濾如「微服務」或「技術隨筆」等類別文章。  

Case 5: 商業模式與 AI 成本  
- Problem: 每次透過 GPT4 做 RAG 回應需消耗大量 Token 開支，成本難以預估或攀升太快。  
- RootCause: GPT 模型 Token 定價較高，若檢索中段落過多或對話頻繁，就會成為長期財務負擔。  
- Resolution: 可透過 GPTs 平台，將推論成本轉嫁給付費用戶，或自行掌控查詢方式、降低不必要 Tokens；也可採較便宜的模型或自行訓練。  
- Example: 作者示範大約 15000 Tokens 花費 0.15 美元，若對話大量進行，可考慮改用 ChatCompletion API 結合 Embedded 查詢微調機制，彈性決定何時使用 GPT4 或其他模型。  

Case 6: 舊式關鍵字 vs. 語意搜尋的差異  
- Problem: 傳統全文檢索容易漏掉語意臨近卻字詞不同的文章，導致查詢落差。  
- RootCause: 關鍵字搜尋無法捕捉文章在不同語句下的近似議題，常需要反覆嘗試關鍵字或手動翻找。  
- Resolution: 結合 Embedding 向量空間，可將同義詞或上下文意涵相近的段落列入範圍，增加覆蓋率與準確度。  
- Example: 談「維持資料一致性」時，不同文章中也有「狀態同步」、「資料更新原子性」，皆能藉向量檢索一次找出。