## FAQ  

Q1: 什麼是 RAG？  
A1: RAG（檢索增強生成）先以向量檢索找出相關內容，再將結果交給 LLM 生成最終回覆。  

Q2: 為何要先把文章向量化？  
A2: 向量化能讓系統辨識文字語意，便於使用自然語言輸入精準搜尋。  

Q3: Kernel Memory 在 RAG 中扮演什麼角色？  
A3: 它提供檢索後端，隨時接收查詢、處理向量搜尋，再回傳分數與文本片段。  

Q4: Chat GPT 與 RAG 如何整合？  
A4: Chat GPT 擔任對話界面，經由 Custom Action 呼叫檢索服務，最後把查詢結果組成回答。  

Q5: Embedding 需要注意哪些成本？  
A5: 模型產生向量需計算 Token 成本，執行大量文字處理時，費用會快速累積。  

Q6: 什麼是 Chunking？  
A6: 指將長文切成小段，讓向量模型更有效處理，避免超出 Token 限制。  

Q7: 為何要在資料中加入 Tags？  
A7: Tags 可用於權限控管與篩選檢索，能精準限定搜尋範圍，提升安全與效率。  

Q8: RAG 有哪些主要應用方向？  
A8: 包括智慧問答、內容摘要、資料導讀、個人化推薦等，都可利用向量檢索強化體驗。  

Q9: 架構師面對 AI 時需要具備哪些觀念？  
A9: 要理解 Prompt Engineering、Embedding、RAG 等流程，並能在系統中靈活整合應用。