## 段落1, 序言與動機  
本段作者首先回顧先前的嘗試，提到了如何利用 GPT-Based 整合應用實現自然語言的購物流程，以及在實際運用中觀察到 AI 可以根據不完整的 API 功能，自動思考並補足細節。此成果不但超出作者原本預期，也帶給他兩個重要的思考方向：未來應用程式如何運用 AI，以及未來的開發流程與角色將如何轉變。藉由「安德魯小舖 GPTs」的初步成功案例，作者開始更加有系統地探討如何在應用程式層面中加入 LLM 智慧，並強調要把 LLM 視作「人」來進行溝通，包含提示、對談邏輯與角色分工等新觀念。  

## 段落2, AI 對軟體開發的衝擊  
本段作者指出掛在 ChatGPT 上的 POC 只是個過渡形式，未來 AI 與應用程式的結合應該更深入且漸進。由於目前 ChatGPT 在速度、用量限制等面向仍有不足，大規模導入需要更穩定可控的機制。因此作者設想了幾種如何把「智慧」逐步加入典型應用程式的路徑：從傳統操作模式開始，先把 LLM 嵌入關鍵環節做輔助，再到操作過程中持續建議，最後達成全對話式操作。這些階段能用更可控、漸進方式，引導開發者與使用者理解並接受 AI 在真實應用情境中扮演的角色。  

## 段落3, 文中使用的資源  
作者於此段先列出文中運用的多項參考，包括他自己實驗的「安德魯小舖 GPTs」整合示範，以及 Microsoft Semantic Kernel、Azure OpenAI、OpenAI Function Calling 與 Assistants API 等官方文件，並且提供其 GitHub 原始碼與相關外部連結。這些資源統整起來，能為想實際動手的讀者帶來更快速的入門通道。作者也引用多篇討論 LLM 架構與程式設計未來的影片與文章，讓讀者得以在更廣闊的視角下思考 AI 技術在軟體世界的衝擊。  

## 段落4, 「安德魯小舖」 的進化 (引言)  
作者在本段提出了進一步重寫「安德魯小舖」的想法：現有的 ChatGPT POC 雖能證明可行性，但要大規模落地，仍需將 LLM 更緊密地整合到應用程式中，且要保留原本系統的穩定性與彈性。他先聚焦「把智慧加到我們熟悉的應用程式」這個概念，將演進過程分成四個階段，分析每個階段在功能與體驗上的變化，並根據實際寫程式的嘗試去佐證可行性。作者同時呼應開發者角色要調整思維，將 LLM 視為能透過自然語言「對談」與「代理」的夥伴，並留意在技術選擇與可行性評估上的思維轉變。  

## 段落5, 1-1: 傳統操作模式作為對照組  
為了對比傳統操作流程，本段描述了一個最基礎的 Console App 範例：透過選單式（或數字指令式）互動，讓使用者輸入指令來查看商品、加入購物車、結帳等。作者特別強調這就是現今大多數應用的使用方式，並無任何智慧輔助。它成為後續逐步加入 AI 「智慧化」的起點。此段也透露作者用截圖方式演示最原始的購物流程，期望能讓讀者明確看見後面導入 LLM 所帶來的使用者體驗差異。  

## 段落6, 1-2: 在關鍵環節加 AI 風險評估  
作者在此段聚焦說明如何在結帳等「關鍵操作」前，透過 LLM 產生個人化的判斷與建議。他利用 System Prompt 來定義「店長」角色，為 LLM 設計相應的 SOP 模型，並在使用者結帳時把購物車與購買註記合併送入 Prompt。作者示範了若購買酒類且出現未成年疑慮，AI 即會回傳 HINT 提示與注意事項，使使用者能在交易前重新檢查。這套機制依賴語言模型對常識的理解與上下文推論，不必再由開發人員寫死繁雜的條件判定，也強調了 Prompt 工程的重要性。  

## 段落7, 1-3: 全程輔助的操作提示 (Copilot 概念)  
本段進一步將通路從「關鍵時刻」延伸至「全程」。作者舉 GitHub Copilot 為例，說明若能在整個操作過程中即時給建議，體驗將更加直覺。他在 Console UI 背後默默更新使用者每次操作細節給 LLM，如果檢測到異常或潛在疑問，才由 LLM 主動在界面跳出提示。如此可實現類「Shop Copilot」的使用體驗，既不干擾日常操作，又能在使用者反覆加減同一商品時提出溫馨提醒。作者指出此功能不易以傳統手段實作，是 LLM 透過文字理解高維度情境的價值展現。  

## 段落8, 1-4: 完整對話式自動化操作  
承接前面漸進的概念，本段以「安德魯小舖」為例，示範了最理想的願景：使用者僅需自然語言下單，AI 就能解析並呼叫後端 API 完成加入購物車、計算預算、安排商品數量及結帳確認等一連串行為。作者強調此階段最重要的突破是 AI 有能力從對話中自動對應「功能呼叫」與「參數」，如此即可實現像 ChatGPT Plugins 那種全對話式操作體驗。此段範例清楚顯示 LLM 如何根據使用者需求拆解並呼叫多個後端函式，最後整合結果並回饋給使用者。  

## 段落9, 探索 LLM 應用的架構 (前言)  
作者在進入第二段主題前，先指出 AI 帶來的改變不只是人機互動界面，而是整個系統架構都將重新調整，如 Knowledge 累積機制、LLM 與外部 API 的溝通方式，以及記憶管理。Microsoft 已經提出了 Semantic Kernel 以建議如何在應用程式中妥善引入 LLM，並探討如何用 RAG 為 AI 提供龐大更即時的知識庫。作者也強調，要先分清楚哪部分適合「演算法式」精準處理，哪部分需要 LLM 等「智慧式」判斷。  

## 段落10, 2-1 與 2-2: LLM 之於短期與長期記憶  
本段闡述 LLM 與傳統三層架構差異。LLM 主要分為 Prompt + Model，預設無狀態故需「Chat History」維持短期記憶；若要補足知識盲點，則需用 RAG 結合向量資料庫建構「長期記憶」，以便在龐雜資訊中做語意檢索，避免在 Prompt 中放過多資料。作者透過人腦聯想機制類比，強調 LLM 善於自然語言推理，但仍需要外部記憶體來對應客製化或大型知識。  

## 段落11, 2-3: Skills/Plugins 與自由執行任務  
作者於此段闡述 LLM 若想真正「做事」而非僅回話，就需配合外部函式或 API，也就是 Semantic Kernel 稱為 Plugins（舊版稱 Skills）。Plugins 透過自然語言描述函式用途、參數與回傳值，讓 LLM 可自行決策要呼叫哪個函式及如何組合參數，攻克過往「AI 只能對話」的局限。作者展示了安德魯小舖的多個 ShopFunction_* 範例，令 LLM 可自動呼叫「AddItemToCart」或「Checkout」等功能，形成在程式碼之外的自然語言調度機制。他也提醒要依業務邏輯謹慎設計 Plugins，避免因為 API 過多而導致 LLM 誤判或濫用資源。  

## 段落12, 2-4: Persona 與角色指令  
承接前述 Skills 概念，本段作者提到要讓 LLM 有一致行為並扮演特定角色，就得在 Prompt 內明確定義「Persona」。在更多進階場景下還可整合個人化資訊（例如用戶曆、地址簿等）成本地 RAG，以實現真正量身訂製的回應。作者則在 POC 中使用較簡易的「店長」對談設定，說明 Persona 與 Prompt Engineering 是讓 LLM 表現穩定、避免失控的關鍵。  

## 段落13, 2-5: 架構全貌與 Semantic Kernel  
作者於此段以總覽圖示為輔，闡述實際的實作路徑：LLM 位於核心，周圍透過插件化 Skills 與向量資料庫來處理知識檢索，並借助 Prompt（含 Persona、系統設定等）來決定 LLM 如何解析需求。同時用 Memory、Chat History 為 LLM 提供短期上下文。Microsoft Semantic Kernel 與 LangChain 等框架正是把這些概念組裝在一起，方便開發者用少量程式實現複雜的 AI 驅動邏輯。作者也點出開發者要刻意優化 Prompt，以降低 Token 消耗、提高回應品質。  

## 段落14, 未來發展 (個人觀點)  
本段作者暢談他對程式開發走向的想像：隨著 LLM 能自動生成並執行程式碼，並逐漸突破幻覺、運算成本等限制，可能導致「以自然語言編寫程式」取代傳統的撰寫語法。回顧昔日語言與工具的演化，作者認為類似 Smalltalk「物件間訊息傳遞」顛覆式思維或許會在未來十年實現。開發者不必恐慌，而應適應新生態，將焦點轉向 Prompt 或建構 Plugins 功能，因為 AI 雖理解通用知識卻還需人類定義專業邏輯。  

## 段落15, 結語  
作者在最後強調，面對 LLM 難以百分之百可預測或可能出現幻覺問題，企業及開發者可類比「面試工程師」的容錯理解。只要流程、架構及交互規劃妥善，AI 雖可能有失誤，但仍能創造前所未見的生產力與效率。人類社會歷經多次技術跳躍，總能在新工具與新文化之間找到平衡。AI 亦然，重點在如何分辨精準執行與智慧判斷的邊界，並漸進改造應用程式的邏輯。對於希望打造「智慧化」應用的開發者，作者建議先理解 LLM 基本特性與框架，再考慮漸進式整合，最終在不犧牲穩定與商業價值的前提下，發揮 AI 的潛力。